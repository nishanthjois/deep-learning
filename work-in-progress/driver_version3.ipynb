{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 220, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 108, 24)   1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 31, 108, 24)   0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 52, 36)    21636       elu_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 14, 52, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 14, 52, 36)    0           elu_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 24, 48)     43248       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 5, 24, 48)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 22, 64)     27712       elu_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 3, 22, 64)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 3, 22, 64)     0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 20, 64)     36928       elu_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1280)          0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_5 (ELU)                      (None, 1280)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1164)          1491084     elu_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_6 (ELU)                      (None, 1164)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           116500      elu_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_7 (ELU)                      (None, 100)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            5050        elu_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_8 (ELU)                      (None, 50)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            510         elu_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_9 (ELU)                      (None, 10)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 10)            0           elu_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             11          dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,744,503\n",
      "Trainable params: 1,744,503\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "50432/50531 [============================>.] - ETA: 0s - loss: 0.0513Epoch 00000: val_loss improved from inf to 0.05163, saving model to model29.h5\n",
      "50531/50531 [==============================] - 298s - loss: 0.0513 - val_loss: 0.0516\n",
      "Epoch 2/30\n",
      "22272/50531 [============>.................] - ETA: 145s - loss: 0.0499"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, Dense, Flatten, Dropout, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import ELU,Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "\n",
    "def resize_image(image_path):\n",
    "    path = image_path.replace(' ', '')\n",
    "    img = imread(path)\n",
    "    \n",
    "    row,col,channels=img.shape\n",
    "    top=int(row*0.35)\n",
    "    bottom = int(row*0.875)\n",
    "    img = img[top:bottom,:]\n",
    "    #img = imresize(img, (32, 32))\n",
    "    img = cv2.resize(img, (220,66), interpolation=cv2.INTER_AREA)\n",
    "    img = add_random_shadow(img)\n",
    "    return img\n",
    "\n",
    "def add_random_shadow(image):\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    #random_bright = .25+.7*np.random.uniform()\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    image = cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)\n",
    "    return image\n",
    "\n",
    "# def trans_image(image,steer,trans_range):\n",
    "#     # Translation\n",
    "#     tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "#     steer_ang = steer + tr_x/trans_range*2*.2\n",
    "#     tr_y = 40*np.random.uniform()-40/2\n",
    "#     #tr_y = 0\n",
    "#     Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "#     image_tr = cv2.warpAffine(image,Trans_M,(220,66))\n",
    "    \n",
    "#     return image_tr,steer_ang\n",
    "\n",
    "def get_model():\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\t#adam = Adam(lr=0.001)\n",
    "\n",
    "\t# Nvidia\n",
    "\tmodel.add(Lambda(lambda x: x/127.5 - 1., input_shape=(66, 220, 3), output_shape=(66, 220, 3)))\n",
    "\tmodel.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal'))\n",
    "\tmodel.add(ELU())\n",
    "\tmodel.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal'))\n",
    "\tmodel.add(ELU())\n",
    "\t#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', dim_ordering='default'))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal'))\n",
    "\tmodel.add(ELU())\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init='he_normal'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(ELU())   \n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init='he_normal'))\n",
    "\t#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', dim_ordering='default'))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(ELU())\n",
    "\tmodel.add(Dense(1164, init='he_normal'))\n",
    "\tmodel.add(ELU())\n",
    "\tmodel.add(Dense(100, init='he_normal'))\n",
    "\tmodel.add(ELU())\n",
    "\tmodel.add(Dense(50, init='he_normal'))\n",
    "\tmodel.add(ELU())\n",
    "\tmodel.add(Dense(10, init='he_normal'))\n",
    "\tmodel.add(ELU())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, init='he_normal'))\n",
    "\n",
    "\t# Use the Adam optimizer to optimize the mean squared error\n",
    "\t#model.compile(optimizer=adam, loss=\"mse\")\t\n",
    "\n",
    "\treturn model\n",
    "\n",
    "# def a_model():\n",
    "#     model = Sequential([\n",
    "#         BatchNormalization(input_shape=(32, 32, 3)),\n",
    "#         Conv2D(32, 3, 3, activation='relu', border_mode='same'),\n",
    "#         Conv2D(32, 3, 3, activation='relu'),\n",
    "#         MaxPooling2D(pool_size=(2, 2)),\n",
    "#         Dropout(0.25),\n",
    "#         Conv2D(64, 3, 3, activation='relu', border_mode='same'),\n",
    "#         Conv2D(64, 3, 3, activation='relu'),\n",
    "#         MaxPooling2D(pool_size=(2, 2)),\n",
    "#         Dropout(0.25),\n",
    "#         Flatten(),\n",
    "#         Dense(512, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(1)\n",
    "#     ])\n",
    "#     return model\n",
    "\n",
    "# load the data\n",
    "# driving_log = pd.read_csv('driving_log.csv')\n",
    "# image_paths = pd.concat([driving_log['center'], driving_log['left'], driving_log['right']])\n",
    "# image_paths = np.array(image_paths, dtype=pd.Series)\n",
    "# mirror_paths = driving_log['center']\n",
    "# mirror_paths = np.array(mirror_paths, dtype=pd.Series)\n",
    "# angles = pd.concat([driving_log['steering'], driving_log['steering'] + 0.08, driving_log['steering'] - 0.08,\n",
    "#                    -driving_log['steering']])\n",
    "# angles = np.array(angles, dtype=pd.Series)\n",
    "\n",
    "driving_log = pd.read_csv('driving_log.csv')\n",
    "image_paths = pd.concat([driving_log['center'], driving_log['left'], driving_log['right']])\n",
    "image_paths = np.array(image_paths, dtype=pd.Series)\n",
    "mirror_paths = driving_log['center']\n",
    "mirror_paths = np.array(mirror_paths, dtype=pd.Series)\n",
    "\n",
    "angles = pd.concat([driving_log['steering'], driving_log['steering'] + 0.2, driving_log['steering'] - 0.2,\n",
    "                   -driving_log['steering']])\n",
    "angles = np.array(angles, dtype=pd.Series)\n",
    "\n",
    "\n",
    "# preprocess images\n",
    "images = [resize_image(path) for path in image_paths]\n",
    "images.extend([np.fliplr(resize_image(path)) for path in mirror_paths])\n",
    "#images.extend([resize_image(path) for path in mirror_paths1])\n",
    "images = np.array(images)\n",
    "angles = np.array([np.asarray([angle], np.float32) for angle in angles])\n",
    "\n",
    "#images,angles=trans_image(images,angles,0.3)\n",
    "\n",
    "images_training, images_validation, angles_training, angles_validation = train_test_split(images, angles, test_size=0.2,\n",
    "                                                                                          random_state=42)\n",
    "nb_training = images_training.shape[0]\n",
    "nb_validation = images_validation.shape[0]\n",
    "nb_epoch = 30\n",
    "\n",
    "#  train the model\n",
    "#my_model = a_model()\n",
    "my_model= get_model()\n",
    "my_model.summary()\n",
    "my_model.compile(optimizer=Adam(lr=0.0001), loss='mse')\n",
    "generator = ImageDataGenerator(width_shift_range=0.2, fill_mode='nearest',shear_range=0.2)\n",
    "#generator.fit(images_training)\n",
    "\n",
    "# only save the best weights\n",
    "checkpoint = ModelCheckpoint('model29.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1)\n",
    "callbacks = [early_stop, checkpoint]\n",
    "my_model.fit_generator(generator.flow(images_training, angles_training, batch_size=128), nb_training, nb_epoch,\n",
    "                       validation_data=generator.flow(images_validation, angles_validation, batch_size=128),\n",
    "                       callbacks=callbacks, nb_val_samples=nb_validation)\n",
    "\n",
    "# save the model\n",
    "with open(\"model29.json\", \"w\") as json_file:\n",
    "    json_file.write(my_model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def trans_image(image,steer,trans_range):\n",
    "#     # Translation\n",
    "#     tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "#     steer_ang = steer + tr_x/trans_range*2*.2\n",
    "#     tr_y = 40*np.random.uniform()-40/2\n",
    "#     #tr_y = 0\n",
    "#     Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "#     image_tr = cv2.warpAffine(image,Trans_M,(cols,rows))\n",
    "    \n",
    "#     return image_tr,steer_ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40180,)\n"
     ]
    }
   ],
   "source": [
    "# driving_log = pd.read_csv('driving_log.csv')\n",
    "# image_paths = pd.concat([driving_log['center'], driving_log['left'], driving_log['right']])\n",
    "# image_paths = np.array(image_paths, dtype=pd.Series)\n",
    "# mirror_paths = driving_log['center']\n",
    "# mirror_paths = np.array(mirror_paths, dtype=pd.Series)\n",
    "# mirror_paths1 = driving_log['right']\n",
    "# mirror_paths1 = np.array(mirror_paths1, dtype=pd.Series)\n",
    "# angles = pd.concat([driving_log['steering'], driving_log['steering'] + 0.08, driving_log['steering'] - 0.08,\n",
    "#                    -driving_log['steering'],driving_log['steering'] - 0.1])\n",
    "# angles = np.array(angles, dtype=pd.Series)\n",
    "\n",
    "# print (angles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nvidia model:\n",
    "# Epoch 20/20\n",
    "# 25600/25715 [============================>.] - ETA: 0s - loss: 0.0223Epoch 00019: val_loss did not improve\n",
    "# 25715/25715 [==============================] - 222s - loss: 0.0223 - val_loss: 0.0208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images = [resize_image(path) for path in image_paths]\n",
    "# images.extend([np.fliplr(resize_image(path)) for path in mirror_paths])\n",
    "# images.extend([resize_image(path) for path in mirror_paths1])\n",
    "# images = np.array(images)\n",
    "# angles = np.array([np.asarray([angle], np.float32) for angle in angles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9897bcf82cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(32144, 66, 220, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "#  print(images.shape)#(32144, 66, 220, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# images,angles=trans_image(images,angles,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  print(images.shape)#(32144, 66, 220, 3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
