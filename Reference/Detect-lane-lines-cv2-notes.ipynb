{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding corners:\n",
    "http://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.findChessboardCorners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding corners:\n",
    "# http://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.findChessboardCorners\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# prepare object points\n",
    "nx = 8\n",
    "ny = 6\n",
    "\n",
    "# Make a list of calibration images\n",
    "fname = 'calibration_test.png'\n",
    "img = cv2.imread(fname)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find the chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "# If found, draw corners\n",
    "if ret == True:\n",
    "    # Draw and display the corners\n",
    "    cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Correcting distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# Find object and image points\n",
    "# objpoints = []\n",
    "# imgpoints = []\n",
    "\n",
    "# gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# objp = np.zeros((6*8,3),np.float32)\n",
    "# objp[:,:2]=np.mgrid[0:8,0:6].T.reshape(-1,2)\n",
    "\n",
    "# ret,corners = cv2.findChessboardCorners(gray,(8,6),None)\n",
    "\n",
    "# if ret == True:\n",
    "#     imgpoints.append(corners)\n",
    "#     objpoints.append(objp)\n",
    "    \n",
    "#     img = cv2.drawChessboardCorners(img,(8,6),corners,ret)\n",
    "    \n",
    "# # Read in the saved objpoints and imgpoints\n",
    "# dist_pickle = pickle.load( open( \"wide_dist_pickle.p\", \"rb\" ) )\n",
    "# objpoints = dist_pickle[\"objpoints\"]\n",
    "# imgpoints = dist_pickle[\"imgpoints\"]\n",
    "\n",
    "\n",
    "# Read in an image\n",
    "img = cv2.imread('test_image.png')\n",
    "\n",
    "# TODO: Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    ret,mtx,dist,rvecs,tvecs = cv2.calibrateCamera(objpoints, imgpoints,img.shape[0:2],None,None)\n",
    "    undist = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    return undist\n",
    "\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Perspective Transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Compute the perspective transform, M, given source and destination points:\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Compute the inverse perspective transform:\n",
    "\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "Warp an image using the perspective transform, M:\n",
    "\n",
    "warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Solution to Undistort and Transform quiz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " Define a function that takes an image, number of x and y points, \n",
    "# camera matrix and distortion coefficients\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Convert undistorted image to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # Search for corners in the grayscaled image\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    if ret == True:\n",
    "        # If we found corners, draw them! (just for fun)\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        # Choose offset from image corners to plot detected corners\n",
    "        # This should be chosen to present the result at the proper aspect ratio\n",
    "        # My choice of 100 pixels is not exact, but close enough for our purpose here\n",
    "        offset = 100 # offset for dst points\n",
    "        # Grab the image shape\n",
    "        img_size = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "        # For source points I'm grabbing the outer four detected corners\n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "        # For destination points, I'm arbitrarily choosing some points to be\n",
    "        # a nice fit for displaying our warped result \n",
    "        # again, not exact, but close enough for our purposes\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "        # Given src and dst points, calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        # Warp the image using OpenCV warpPerspective()\n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "You need to pass a single color channel to the cv2.Sobel() function, so first convert to grayscale:\n",
    "\n",
    "gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "Note: Make sure you use the correct grayscale conversion depending on how you've read in your images. Use cv2.COLOR_RGB2GRAY if you've read in an image using mpimg.imread() or cv2.COLOR_BGR2GRAY if you've read in an image using cv2.imread().\n",
    "\n",
    "Calculate the derivative in the x-direction (the 1, 0 at the end denotes x-direction):\n",
    "\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "\n",
    "Calculate the derivative in the y-direction (the 0, 1 at the end denotes y-direction):\n",
    "\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "\n",
    "Calculate the absolute value of the x-derivative:\n",
    "\n",
    "abs_sobelx = np.absolute(sobelx)\n",
    "\n",
    "Convert the absolute value image to 8-bit:\n",
    "\n",
    "scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "Note: It's not entirely necessary to convert to 8-bit (range from 0 to 255) but in practice, it can be useful in the event that you've written a function to apply a particular threshold, and you want it to work the same on input images of different scales, like jpg vs. png. You could just as well choose a different standard range of values, like 0 to 1 etc.\n",
    "\n",
    "Create a binary threshold to select pixels based on gradient strength:\n",
    "\n",
    "thresh_min = 20\n",
    "thresh_max = 100\n",
    "sxbinary = np.zeros_like(scaled_sobel)\n",
    "sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "plt.imshow(sxbinary, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Read in an image and grayscale it\n",
    "image = mpimg.imread('signs_vehicles_xygrad.png')\n",
    "\n",
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "# Note: calling your function with orient='x', thresh_min=5, thresh_max=100\n",
    "# should produce output like the example image shown above this quiz.\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=100):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "    abs_sx=np.absolute(sobelx)\n",
    "    scaled_sx=np.uint8(255*abs_sx/np.max(abs_sx))\n",
    "    binary_output=np.zeros_like(scaled_sx)\n",
    "    binary_output[(scaled_sx>=thresh_min)&(scaled_sx<=thresh_max)]=1\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    return binary_output\n",
    "    \n",
    "# Run the function\n",
    "grad_binary = abs_sobel_thresh(image, orient='x', thresh_min=30, thresh_max=80)\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(grad_binary, cmap='gray')\n",
    "ax2.set_title('Thresholded Gradient', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is gradient magnitude:\n",
    "http://stackoverflow.com/questions/19815732/what-is-gradient-orientation-and-gradient-magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/M5mSS.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "#The following images shows you the horizontal component:\n",
    "Image(url= \"https://i.stack.imgur.com/M5mSS.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it shows how much the gray levels in your image change in the horizontal direction (it is the direction of positive x, scanning the image from left to right), this change is \"encoded\" in the grey level of the image of the horizontal component: the mean grey level means no change, the bright levels mean change from a dark value to a bright value, the dark levels mean a change from a bright value to a dark value. So, in the above image you see the brighter value in the left part of the circle because it is in the left part of the initial image that you have the black to white transition that gives you the left edge of the disk; similarly, in the above image you see the darker value in the right part of the circle because it is in the right part of the initial image that you have the white to black transition that gives you the right edge of the disk. In the above image, the inner part of the disk and the background are at a mean grey level because there is no change inside the disk and in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make analogous observations for the vertical component, it shows how the image change in the vertical direction, i.e. scanning the image from the top to the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/zjjPU.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following images shows you the vertical component:\n",
    "Image(url=\"https://i.stack.imgur.com/zjjPU.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now combine the two components in order to get the magnitude of the gradient and the orientation of the gradient.\n",
    "\n",
    "The following image is the magnitude of the gradient:\n",
    "Again, in the above image the change in initial image is encoded in the gray level: here you see that white means an high change in the initial image while black means no change at all. So, when you look at the image of the magnitude of the gradient you can say \"if the image is bright it means a big change in the initial image; if it is dark it means no change or very llittle change\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/foR6C.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.stack.imgur.com/foR6C.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction of the gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The direction of the gradient is simply the arctangent of the y-gradient divided by the x-gradient.  \n",
    "\n",
    "Each pixel of the resulting image contains a value for the angle of the gradient away from horizontal in units of radians, covering a range of −π/2 to π/2. An orientation of 0 implies a horizontal line and orientations of +/−π/2 imply vertical lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in an image\n",
    "image = mpimg.imread('road.png')\n",
    "\n",
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel, thresh):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely=cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    abs_sobelx=np.absolute(sobelx)\n",
    "    abs_sobely=np.absolute(sobely)\n",
    "    orient = np.arctan2(abs_sobely,abs_sobelx)\n",
    "    binary_output=np.zeros_like(orient)\n",
    "    binary_output[(orient>=thresh[0])&(orient<=thresh[1])]=1\n",
    "    \n",
    "    return binary_output\n",
    "    \n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient=='x':\n",
    "        sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "    if orient=='y':\n",
    "        sobelx=cv2.Sobel(gray,cv2.CV_64F,0,1)    \n",
    "        \n",
    "    abs_sx=np.absolute(sobelx)\n",
    "    scaled_sx=np.uint8(255*abs_sx/np.max(abs_sx))\n",
    "    binary_output=np.zeros_like(scaled_sx)\n",
    "    binary_output[(scaled_sx>=thresh[0])&(scaled_sx<=thresh[1])]=1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=9)\n",
    "    sobely=cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=9)\n",
    "    grad = np.sqrt(sobelx**2 + sobely**2)\n",
    "    s9bit = np.uint8(255*grad/np.max(grad))\n",
    "    binary_output = np.zeros_like(s9bit)\n",
    "    mint = mag_thresh[0]\n",
    "    maxt=mag_thresh[1]\n",
    "    binary_output[(s9bit>=mint)&(s9bit<=maxt)]=1\n",
    "    return binary_output\n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "# Apply each of the thresholding functions\n",
    "gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(50, 120))\n",
    "grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(50, 120))\n",
    "mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(50, 100))\n",
    "dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0, 1.7))\n",
    "    \n",
    "# Run the function\n",
    "combined = np.zeros_like(dir_binary)\n",
    "combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "#combined[((gradx == 1))] = 1\n",
    "\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(combined, cmap='gray')\n",
    "ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
